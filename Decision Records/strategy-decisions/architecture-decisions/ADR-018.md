# ADR-018: AI-Powered Forecasting and Capacity Signals

**Status**: Accepted  
**Date**: YYYY-MM-DD  
**Deciders**: Chief Architect, Head of AI/ML, Treasury Operations Lead, CTO  
**Context Level**: Forecasting, ML Architecture, and Operational Resiliency

## Context

Capacity planning and volume forecasting are critical for optimizing FX operations, staffing, SLA adherence, and exception response readiness. Traditional forecasting approaches are often:

- Spreadsheet-driven, manual, and backward-looking  
- Lacking real-time visibility into changing operational patterns  
- Unintegrated with exception queues or AI insights  
- Poorly adapted to novel drivers (e.g., global volatility, AI load, seasonality shifts)

A machine learning-driven approach can provide more granular and adaptive signals to help desks and ops leaders proactively manage risk and workloads.

## Decision

Adopt an **AI-powered forecasting strategy** that combines:

- Historical time series data (volumes, case counts, SLA compliance)  
- Feature-enriched signals (e.g., desk type, time of day, product class, macro triggers)  
- Model ensembles (e.g., XGBoost, Prophet, LSTM, TabNet) deployed to inference APIs  
- Capacity signals surfaced in dashboards, alerts, and orchestration flows (e.g., staffing workflows)

All forecasts will include confidence intervals, metadata tags, and last-trained timestamps for audit and retraining governance.

## Rationale

- **CIO Alignment**: Enables predictive staffing, forward-looking performance SLAs, and operational confidence  
- **CTO Alignment**: Supports automation, AIOps integration, and dashboard observability  
- **Chief Architect Alignment**: Connects ML pipelines to business domains through reusable interfaces and traceable model governance

## Consequences

### Benefits

- **Proactive Ops Planning**: Desk leads can plan workload shifts, flag emerging risks, and rebalance capacity  
- **Reusable ML Assets**: Forecasting modules can be integrated into multiple orchestration use cases  
- **Decision Confidence**: Stakeholders can inspect input features, drivers, and confidence levels  
- **Retraining Cadence**: Models can be automatically retrained as new volume data is ingested

### Trade-Offs

- **Model Drift**: Needs active monitoring and retraining governance  
- **Operational Uplift**: Forecasts must be translated into clear, actionable capacity plans  
- **Explainability Balance**: Some ensemble models require surrogate explanations (e.g., SHAP) for feature impact

## Alternatives Considered

- **Manual Forecasting by Business Users**  
  Slow, subjective, and unscalable across high-volume operational domains.

- **Fixed Rules (e.g., average of past 4 weeks)**  
  Simple but unable to adapt to shocks, volatility, or macroeconomic events.

## Lifecycle and Governance

- Forecasting models must log training data version, feature importance, and inference metadata  
- Outputs must be pushed to observability dashboards and optionally to orchestration triggers  
- SLA violations must be retrospectively scored against predicted capacity gaps  
- Forecast retraining thresholds (e.g., RMSE, drift score) must be configured per domain

## Tags

`#forecasting`, `#mlops`, `#capacity-planning`, `#ai-ops`, `#signal-architecture`, `#sla`, `#model-traceability`
