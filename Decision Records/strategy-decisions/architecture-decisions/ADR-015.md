# ADR-015: Data Lake Strategy for Model Training and Auditability

**Status**: Accepted  
**Date**: YYYY-MM-DD  
**Deciders**: Chief Architect, Head of Data Engineering, CDO, Head of ML Engineering  
**Context Level**: Enterprise Data Architecture and AI Lifecycle Management

## Context

Effective AI requires a robust foundation of trustworthy, well-governed data. This includes:

- Raw and refined operational data for training ML models  
- Historical records of exception workflows and outcomes  
- Semantic tagging for audit, explainability, and versioning  
- Scalable access patterns for batch pipelines and LLM-grounded retrieval

Siloed data stores and API-only ingestion pipelines fall short of enabling transparency, reuse, and model reproducibility across teams.

## Decision

Adopt a **centralized, cloud-native data lake** architecture as the system of record for all data powering AI workflows. This includes:

- Raw, curated, and derived zones (bronze, silver, gold)  
- Immutable storage with append-only logging and schema versioning  
- Access policies based on business domain, sensitivity, and role  
- Audit trails for every dataset mutation, training input, and derived feature

Preferred technologies include **Amazon S3 + AWS Glue Catalog**, **Lake Formation**, **Iceberg/Delta format**, and **cross-account access patterns**.

## Rationale

- **CIO Alignment**: Promotes unified data strategy and supports compliance (audit, lineage, retention)  
- **CTO Alignment**: Enables standardized, scalable data access across teams and cloud-native tooling  
- **Chief Architect Alignment**: Fits BDAT framework, supports AI reproducibility, and enables modular architecture for ingestion, transformation, and consumption

## Consequences

### Benefits

- **Model Reproducibility**: Historical versions of training data and features can be retrieved exactly as used  
- **Governance-Ready**: Data classification, encryption, access control, and lineage tracking can be enforced at scale  
- **Cross-Use Enablement**: Forecasting, audit, dashboards, and ML training can reuse the same governed layers  
- **ETL Simplification**: Enables decoupled transformation pipelines that read/write structured zones

### Trade-Offs

- **Storage Cost Management**: Must implement lifecycle policies and data tiering for cold zones  
- **Upfront Design Investment**: Zone structure, catalog tagging, and pipeline architecture must be planned early  
- **Performance Considerations**: Requires optimization for query patterns and data formats (e.g., partitioning, compression)

## Alternatives Considered

- **Data Warehouse Only Strategy (e.g., Redshift, Snowflake)**  
  Good for BI but unsuitable for raw ingestion, ML reproducibility, or write-heavy workloads.

- **Decentralized Team-Specific Stores**  
  Causes data drift, inconsistent semantics, and fragmented governance.

## Lifecycle and Governance

- All training data must reference versioned snapshots in the gold zone  
- ML metadata (features, labels, model inputs) must be traceable to lake tables  
- Data pipelines must conform to schema evolution and access boundary checks  
- Lineage metadata must be surfaced in data catalogs and AI audit reports

## Tags

`#data-lake`, `#ai-training`, `#governance`, `#auditability`, `#iceberg`, `#glue-catalog`, `#mlops`, `#bdarchitecture`
