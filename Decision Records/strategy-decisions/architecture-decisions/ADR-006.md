# ADR-006: RAG Stack Design with Retrieval + Prompt Separation

**Status**: Accepted  
**Date**: YYYY-MM-DD  
**Deciders**: Chief Architect, Head of AI/ML, Platform Engineering Lead  
**Context Level**: AI Platform Architecture and Enterprise Prompt Engineering

## Context

Retrieval-Augmented Generation (RAG) has emerged as a key pattern for grounding LLM outputs in enterprise data. However, many implementations tightly couple:

- Data retrieval logic with prompt templates  
- Embedded query logic with model selection  
- System behaviors with model-specific hacks

This results in fragile, un-auditable systems that cannot scale across business domains, models, or compliance requirements.

## Decision

Adopt a **separation of concerns model** for the RAG stack:

- Retrieval logic is encapsulated in a dedicated service or module (Retriever)
- Prompt templates are defined independently, parameterized with structured inputs
- A RAG Orchestrator component coordinates retrieval → transformation → model invocation → post-processing

## Rationale

- **CIO Alignment**: Enhances explainability and audit readiness across AI-driven decisions  
- **CTO Alignment**: Decouples runtime services, enabling versioning, testing, and reuse across teams  
- **Chief Architect Alignment**: Aligns with modular design principles, promotes traceability, and simplifies future model transitions

## Consequences

### Benefits

- **Explainability**: Every input to the LLM can be traced to structured, versioned retrieval logic  
- **Reusability**: Prompts can be reused across tasks, retrievers across documents or metadata types  
- **Composability**: Enables a standardized interface for chaining grounding → prompting → formatting → response routing  
- **Governance**: Allows separate review tracks for prompt content and data retrieval coverage

### Trade-Offs

- **Integration Overhead**: Requires building orchestration glue across components  
- **Tooling Requirements**: May require internal libraries for prompt formatting, input templating, and trace logging  
- **Team Coordination**: Retrieval and prompt engineers must work together via well-defined interfaces

## Alternatives Considered

- **Monolithic Prompt Services**  
  Fast to build but quickly become unmanageable with prompt and retrieval logic intertwined.

- **Framework-coupled RAG stacks (e.g., LangChain only)**  
  Great for prototyping, but limits control over observability, fallback logic, or enterprise patterns.

## Lifecycle and Governance

- Each prompt must be defined with a versioned `.prompt.md` or YAML structure  
- Retrieval modules must be tagged with domain scope, source metadata, and access policy alignment  
- All RAG orchestrations must log input content, prompt ID, retriever version, and LLM output

## Tags

`#rag-architecture`, `#prompt-engineering`, `#retrieval-separation`, `#explainability`, `#llm-traceability`, `#ai-governance`
