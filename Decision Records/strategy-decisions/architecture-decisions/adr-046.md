# ADR-046: Secure Tokenization for PII in LLM Workflows

**Status**: Accepted  
**Date**: YYYY-MM-DD  
**Deciders**: Chief Architect, Chief Information Security Officer (CISO), AI Risk Officer  
**Context Level**: AI Safety, Data Privacy, LLM Compliance

## Context

LLM-based applications often involve processing unstructured or semi-structured text that may include sensitive Personal Identifiable Information (PII), such as names, emails, IDs, or financial data. Risks include:

- Accidental PII exposure through model responses  
- Data leakage to external APIs during inference  
- Regulatory non-compliance (GDPR, HIPAA, CCPA)  
- Lack of explainability around data usage and retention

To address these, a robust **tokenization and detokenization mechanism** is needed for managing PII throughout the LLM lifecycle.

## Decision

Implement a **Secure Tokenization Framework** for PII in LLM pipelines to ensure privacy preservation, auditability, and response control.

### Core Features:

1. **PII Detection and Tokenization Pre-Inference**  
   - Use rule-based and ML models (e.g., regex, spaCy, Amazon Comprehend, Presidio)  
   - Replace sensitive fields with tokens (e.g., `{{NAME_1}}`, `{{ACCOUNT_3}}`)

2. **Secure Mapping Vault**  
   - Maintain token-to-original mappings in a secure vault (e.g., HashiCorp Vault, AWS Secrets Manager)  
   - Access controlled, encrypted at rest and in transit

3. **Inference and Post-Processing**  
   - LLM receives redacted input with tokens only  
   - Responses inspected before detokenization to validate and sanitize content

4. **Audit Trail and Governance**  
   - Log all tokenization and detokenization events with user, timestamp, model, and token metadata  
   - Enable traceability for internal audits and data subject requests

5. **Policy Enforcement**  
   - Tokens for regulated PII types (e.g., SSNs) never detokenized automatically  
   - Manual or rule-based override only with just-in-time access

## Rationale

- **CIO Alignment**: Ensures enterprise data privacy and regulatory compliance  
- **CTO Alignment**: Mitigates risk of accidental exposure in APIs or prompts  
- **Chief Architect Alignment**: Codifies privacy-by-design across LLM architecture

## Consequences

### Benefits

- Enables safer LLM adoption across sensitive domains  
- Reduces legal and reputational risks from data misuse  
- Makes privacy compliance enforceable via automation  
- Supports red-teaming and explainability audits

### Trade-Offs

- Added complexity in pipeline development and prompt engineering  
- Requires secure, scalable storage for token vault  
- Slight latency overhead for tokenization and validation

## Alternatives Considered

- Prompt-level disclaimers or "do not answer" instructions  
  → Not enforceable; models may still leak PII

- Manual PII redaction  
  → Not scalable or consistent; high risk of omissions

## Lifecycle and Governance

- Token patterns and PII categories maintained by security and privacy team  
- Vault access audited and alerts configured for abnormal usage  
- Monthly token vault cleanup and retention policy enforcement  
- Detokenization whitelist reviewed by data privacy board

## Tags

`#pii` `#llm-security` `#tokenization` `#data-privacy` `#gdpr` `#hipaa` `#safe-llm` `#redaction` `#compliance`
