# ADR-004: Use of Apache Flink for Real-Time Stream Processing

**Status**: Accepted  
**Date**: YYYY-MM-DD  
**Deciders**: Chief Architect, Head of Data Engineering, CTO  
**Context Level**: Enterprise Streaming & Event Processing Architecture

## Context

As digital platforms scale, they generate high-velocity event streams from operational systems (e.g., transaction logs, exception events, audit trails, anomaly signals). Processing these streams in real time enables:

- Faster SLA breach detection  
- Responsive exception triaging  
- Low-latency user notifications and routing  
- Real-time dashboards and alerts  
- Online feature extraction for AI inference

Traditional batch pipelines or API polling mechanisms fall short when real-time responsiveness and fine-grained event ordering are critical.

## Decision

Adopt **Apache Flink** as the standard engine for real-time stream processing tasks. Deployment may occur on:

- **AWS Kinesis Data Analytics for Flink**  
- **Apache Flink on Kubernetes (EKS/GKE/AKS)**  
- **Flink on Amazon EMR or Azure HDInsight**  
- Or through managed services such as Ververica Platform

## Use Case Examples

- Stream-based exception scoring and enrichment  
- Real-time operational SLA monitoring  
- Low-latency desk-level routing workflows  
- Audit event correlation and summarization

## Rationale

- **CIO Alignment**: Enables real-time visibility and rapid mitigation of risks or operational issues  
- **CTO Alignment**: Supports scalable event consumption, event-time logic, and complex stateful computation  
- **Chief Architect Alignment**: Integrates with BDAT stream layer, aligns with Kafka/EventBridge, supports deterministic output and failover

## Consequences

### Benefits

- **Event-Time Semantics**: Supports watermarks, late arrivals, and precise processing windows  
- **Stateful Computation**: Enables counters, aggregates, and timers per event key  
- **Resilience**: Offers checkpointing, restart strategies, and fault recovery  
- **Interoperability**: Works well with Kafka, Kinesis, Iceberg, and external sinks like Redshift or S3

### Trade-Offs

- **Operational Complexity**: Requires specialized monitoring and tuning  
- **Learning Curve**: Higher than lightweight stream frameworks (e.g., Spark Structured Streaming)  
- **Cluster Management**: Stateful apps require persistent storage, scaling policies, and resource tuning

## Alternatives Considered

- **Kafka Streams**  
  Simpler for basic transformation and aggregation, but lacks rich state management and time semantics.

- **AWS Lambda + Kinesis**  
  Easier for atomic functions, but impractical for multi-step, stateful streaming logic.

- **Apache Spark Structured Streaming**  
  Good for lightweight use cases but lacks deep windowing semantics and fine control over state.

## Lifecycle and Governance

- All Flink jobs must include observability hooks, backpressure metrics, and event delay dashboards  
- Streaming jobs should be peer-reviewed, tested with replayed historical data, and logged with business context (e.g., trace_id, source_id)  
- State checkpointing intervals and storage must comply with enterprise data retention and encryption policies

## Tags

`#stream-processing`, `#apache-flink`, `#event-time`, `#low-latency`, `#real-time`, `#exception-routing`
