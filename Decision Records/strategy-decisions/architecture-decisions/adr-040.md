# ADR-040: Common Embedding Index for Multi-Modal Retrieval

**Status**: Accepted  
**Date**: YYYY-MM-DD  
**Deciders**: Chief Architect, AI Platform Lead, Search & Retrieval Lead  
**Context Level**: Vector Retrieval Architecture, RAG, Semantic Search Enablement

## Context

As organizations embrace Retrieval-Augmented Generation (RAG) and AI-powered search, they begin indexing multiple data modalities — documents, chat transcripts, knowledge bases, tables, and logs. This leads to:

- Multiple fragmented vector indices per team or use case  
- Duplicate embeddings and inconsistent retrieval quality  
- Inability to support cross-modal search or response synthesis  
- Inefficient resource usage and governance challenges

A shared, governed embedding store enables consistent, efficient, and scalable multi-modal AI retrieval experiences.

## Decision

Adopt a **Common Embedding Index Architecture** for multi-modal retrieval to support unified semantic search and RAG applications.

### Components and Strategy:

1. **Centralized Vector Store**  
   - Use scalable vector DB (e.g., Pinecone, Weaviate, OpenSearch, Qdrant)  
   - Multi-namespace or tenant-based isolation by domain

2. **Multi-Modal Document Support**  
   - Support for structured, semi-structured, and unstructured inputs  
   - Parsers for PDF, emails, HTML, tables, audio transcripts

3. **Embedding Pipelines**  
   - Modular ingestion pipelines with tokenization, chunking, and embedding  
   - Common embedding models (e.g., OpenAI, Cohere, AWS Titan, BGE, Instructor) with versioning

4. **Metadata and Filters**  
   - Rich metadata schema (e.g., source, org_unit, tag, date_range) for filtered queries  
   - Indexable filters and hybrid search (vector + keyword)

5. **Governance Layer**  
   - Policies for PII/PHI redaction, TTLs, refresh schedules, and usage metrics  
   - Access control on read/write/query via IAM policies

## Rationale

- **CIO Alignment**: Enables search experiences that span organizational knowledge safely  
- **CTO Alignment**: Avoids redundant infrastructure and aligns search capabilities  
- **Chief Architect Alignment**: Establishes common semantic infrastructure for AI across domains

## Consequences

### Benefits

- Accelerates AI agent development with consistent context access  
- Reduces infra duplication and simplifies observability  
- Improves relevance and retrieval fidelity across domains  
- Enables hybrid workflows with structured + unstructured data

### Trade-Offs

- Initial infra setup and governance complexity  
- Must standardize ingestion formats and schemas across teams  
- Embedding model lifecycle management becomes central task

## Alternatives Considered

- Domain-specific vector DBs for each use case  
  → Fast to start, but leads to fragmentation and poor search UX.

- Rely solely on keyword/document search  
  → Fails to support semantic understanding and LLM grounding.

## Lifecycle and Governance

- Embedding pipelines owned by platform ML team  
- Indexes monitored for freshness, latency, and drift  
- CI policies ensure parsing, PII scrub, and chunking compliance  
- Usage dashboards reviewed quarterly by data search governance team

## Tags

`#embedding-index` `#vector-store` `#semantic-search` `#rag` `#multi-modal` `#retrieval` `#llm` `#architecture` `#search-infra`
