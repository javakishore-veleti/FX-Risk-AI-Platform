# ADR-017: Exception Handling with Rule + AI Hybrid Orchestration

**Status**: Accepted  
**Date**: YYYY-MM-DD  
**Deciders**: Chief Architect, Head of Risk Engineering, CTO, Head of AI/ML  
**Context Level**: Workflow Automation, AI Decision Support, and Regulatory Traceability

## Context

Exception workflows (e.g., trade disputes, reconciliation breaks, capacity alerts) are often:

- Highly structured in rule logic (if this, route there)  
- Loosely defined in narrative analysis, cause categorization, or resolution text  
- Subject to strict timelines, SLA policies, and audit expectations

Using only rules leads to brittleness. Using only LLMs leads to non-determinism and low explainability. A hybrid orchestration approach balances traceability with intelligence.

## Decision

Adopt a **Rule + AI Hybrid Orchestration** pattern, where:

- Deterministic routing (based on metadata, thresholds, SLAs) is handled via a rules engine or orchestration service (e.g., Step Functions)  
- LLMs are invoked only for scoped tasks such as:  
  - Narrative summarization  
  - Dispute cause classification  
  - Email response drafting  
- LLM outputs must be passed through guardrails (prompt validation, fallback handling, audit logging)

## Rationale

- **CIO Alignment**: Ensures SLA compliance while introducing AI in an auditable, risk-managed way  
- **CTO Alignment**: Enables continuous improvements to resolution flows without rewriting core business logic  
- **Chief Architect Alignment**: Establishes a composable orchestration model across AI and non-AI domains, with clear ownership and fallback paths

## Consequences

### Benefits

- **Traceability**: Each exception’s path is logged — rules taken, AI prompts executed, outputs stored  
- **Governance**: Risk-sensitive outputs (e.g., customer-facing) are filtered or human-reviewed  
- **Flexibility**: Prompts can evolve while routing rules remain version-locked  
- **User Confidence**: Teams retain control over the exception process with AI assist, not AI override

### Trade-Offs

- **Orchestration Complexity**: Requires coordination between rules engine and LLM service layers  
- **Latency Overhead**: AI calls may introduce delay unless parallelized  
- **Tooling**: Requires integration of logging, retries, model abstraction, and observability per workflow

## Alternatives Considered

- **Rule-Only Workflow**  
  Stable, but brittle and unscalable as workflows increase in edge-case variety.

- **LLM-Only Decision Making**  
  Flexible, but risky for time-sensitive or regulated workflows without fallback logic.

## Lifecycle and Governance

- Orchestration flows must declare when and how LLMs are used, including input sources and fallback logic  
- All LLM responses in exception resolution must be logged with prompt ID, model ID, and version metadata  
- Periodic post-mortems must review false positives/negatives in both rules and AI logic  
- Business teams must approve categories of exception tasks to be AI-assisted

## Tags

`#workflow-automation`, `#exception-handling`, `#hybrid-ai`, `#sla-compliance`, `#step-functions`, `#rules-engine`, `#auditability`, `#llm-governance`
