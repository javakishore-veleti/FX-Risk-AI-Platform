# ADR-019: Auditability Patterns for GenAI Workflows

**Status**: Accepted  
**Date**: YYYY-MM-DD  
**Deciders**: Chief Architect, CISO, Head of Compliance, Head of AI/ML  
**Context Level**: AI Governance, Regulatory Traceability, and Enterprise Risk

## Context

Generative AI (GenAI) introduces unique auditability challenges:

- Prompts and outputs are unstructured, non-deterministic, and mutable  
- Model versions and prompt logic may evolve frequently  
- Business stakeholders, regulators, or auditors may request justifications for actions taken by AI agents  
- Internal review teams may need to assess fairness, tone, factual correctness, or reasoning of GenAI responses

Without a well-defined auditability framework, GenAI use in enterprise workflows may violate explainability mandates, increase regulatory risk, or undermine user trust.

## Decision

Apply structured **auditability patterns** to all GenAI-assisted workflows, including:

- Logging prompt ID, version, template, input variables, and timestamp  
- Logging full model output, token count, and post-processing logic  
- Linking each GenAI output to its downstream action (e.g., routed case, API update, user-visible summary)  
- Role-based access to audit logs, scoped by domain, model, and business criticality  
- Optionally, apply LLM-based self-audit classification (e.g., "was this output factual, on-policy, polite?")

## Rationale

- **CIO Alignment**: Protects enterprise reputation, ensures compliance readiness, and builds trust in AI outcomes  
- **CTO Alignment**: Creates a shared telemetry layer for debugging, drift detection, and data retention  
- **Chief Architect Alignment**: Embeds auditability as a cross-cutting concern, integrated with observability and traceability layers

## Consequences

### Benefits

- **Regulatory Alignment**: Supports explainability mandates (e.g., DORA, EU AI Act)  
- **Review Support**: Enables replay and inspection of GenAI actions during audits or internal review  
- **Model Lifecycle Governance**: Ensures model versions and prompt logic are captured alongside results  
- **Data Quality Feedback**: Logged output can be scored for quality, bias, or hallucinations

### Trade-Offs

- **Storage Volume**: GenAI logs are large and must be managed via retention tiers  
- **Privacy Scope**: Sensitive user data in prompts or responses must be redacted or encrypted  
- **Operational Overhead**: Requires tagging, trace ID correlation, and indexing for searchability

## Alternatives Considered

- **Basic Logging (Only Prompt + Output)**  
  Lacks context, downstream linkage, and searchability; insufficient for enterprise audits.

- **Manual Review of Edge Cases**  
  Reactive, expensive, and non-scalable for high-volume AI workflows.

## Lifecycle and Governance

- All GenAI workflow logs must be stored in a secure, structured format with version metadata  
- Access must be governed via RBAC/ABAC and reviewed quarterly  
- Sampling strategies may be used for high-volume scenarios (e.g., 10% of low-risk cases)  
- Periodic audit readiness checks must validate log completeness and accessibility

## Tags

`#genai`, `#auditability`, `#explainability`, `#ai-governance`, `#compliance`, `#llm-traceability`, `#risk-controls`
