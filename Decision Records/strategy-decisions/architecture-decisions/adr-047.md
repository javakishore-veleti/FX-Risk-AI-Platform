# ADR-047: Layered Prompt Engineering Guidelines for Domain-Specific LLM Use Cases

**Status**: Accepted  
**Date**: YYYY-MM-DD  
**Deciders**: Chief Architect, LLM Product Owner, Prompt Engineering Guild  
**Context Level**: AI Design Patterns, Domain Alignment, LLM Implementation Strategy

## Context

In enterprise settings, LLM prompts must reflect domain-specific terminology, tone, compliance needs, and contextual grounding. Ad-hoc prompt construction leads to:

- Inconsistent performance across similar tasks  
- Over-engineering or under-specification  
- Difficulty debugging or updating prompt behavior  
- Duplication of prompt logic across teams

A structured and reusable framework is needed to guide prompt design based on layers and components of language behavior.

## Decision

Adopt a **Layered Prompt Engineering Guideline** that standardizes how prompts are built, composed, tested, and governed for enterprise use cases.

### Layers and Components:

1. **System Layer**  
   - Defines universal instructions: behavior, tone, persona  
   - Example: “You are a risk analyst assistant specializing in FX trade workflows…”

2. **Context Layer**  
   - Provides grounding content from vector stores, databases, or metadata  
   - Must be curated for relevance, deduplication, and recency

3. **Task Layer**  
   - Explicit user instruction or action formulation  
   - Example: “Summarize the resolution path for trade ID 7923…”

4. **Formatting Layer**  
   - Controls structure of output: JSON schema, tabular text, Markdown  
   - Ensures consistency for downstream system parsing

5. **Constraints Layer**  
   - Safety, length, tone, and compliance filters  
   - Example: “Avoid financial advice; use no more than 150 words.”

## Rationale

- **CIO Alignment**: Aligns AI outputs with business tone, regulatory compliance, and UX standards  
- **CTO Alignment**: Reduces redundancy and accelerates prompt iteration cycles  
- **Chief Architect Alignment**: Establishes modular, maintainable design for enterprise-grade AI agents

## Consequences

### Benefits

- Predictable, reusable prompt behavior across domains and use cases  
- Easier debugging and A/B testing of prompt layers  
- Better alignment with architecture standards for retrieval, context, and output routing  
- Promotes prompt-as-code culture and version control

### Trade-Offs

- Requires upfront training and discipline for engineering teams  
- Needs central prompt library governance and test coverage  
- Slight learning curve for modular design

## Alternatives Considered

- Freestyle prompts written per developer  
  → Leads to drift, confusion, and poor reproducibility

- End-to-end fine-tuned models for each use case  
  → Costly, brittle, and harder to explain or adapt

## Lifecycle and Governance

- Prompt templates managed in version-controlled repo  
- Each prompt reviewed and tested with unit and scenario tests  
- Central prompt catalog with metadata, lineage, and usage tags  
- Quarterly reviews by Prompt Engineering Guild to improve templates

## Tags

`#prompt-engineering` `#llm` `#layered-prompts` `#modular-design` `#ai-patterns` `#enterprise-ai` `#reusability` `#retrieval-augmented-generation`
